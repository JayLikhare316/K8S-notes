TOPICS TO LEARN 

Core Concepts: 
Monolithic vs MicroServices, Kubernetes Architecture, Setup on Local/AWS EC2, kubectl, Pods, Namespaces, Labels ,
Selectors, Annotations 

Workloads:
Deploymnets, StatefulSets, Daemonsets, ReplicaSets, Jobs, CronJobs

Networking:
Cluster Networking, Services, Ingress, Network Policies

Storage:
persistent volume (PV), persistent volume claims (PVC), StorageClasses, ConfigMaps, Secrets 

Scaling and Scheduling:
HPA, VPA, Node Affinity, Taints and Toleration, Resource Quotas, Limit , Probes 

Cluster Administration:
RBAC, Cluster upgrade, Custom Resource Definitions (CRDs)

Monitoring and Logging:
Metrics server, Monitoring tools, Logging tools, Prometheus, Grafana, ELK Stack

Advanced Features:
Operators, Helm, Service Mesh, Kubernetes API

Security:
Pod security Standards (PSS), Image Scanning, Network Policies, Secret Encryption, Network Policies, RBAC

Cloud-Native Kubernetes:
managed Services(EKS, AKS, GKE), Cluster Autoscaler, Spot/Preemptible Nodes.

Debugging and Troubleshooting:
kubectl debugging, Logs, Resource Usage analysis

#############################################################################

Creating Ways of Kubernetes Cluster 
1.kubeadm
2.Minikube (local/ec2)
3.KIND Cluster (kubernetes in docker)
4.EKS/AKS/GKE 

#################################################################################
 
container --> pod --> deployment --> service --> user 

# How to create a namespace 

1. kubectl create ns nginx-ns
2. kubectl run nginx --image=nginx -n nginx-ns    #---> create a pod through CMD in the namespace
3. kubectl get pods -n nginx-ns      #---> to see pods in the namespace
4. kubectl get pods -n nginx-ns -o wide     #---> to see pods in the namespace with more details

# how to enter in pod
1. kubectl exec -it pod/nginx-pod -n nginx-ns -- bash 
z
2.kubectl describe pod nginx-pod -n nginx-ns  #---> to see the details of the pod

## ReplicaSet/ StatefulSet /Deployment

kubectl scale deployment/nginx-deploy -n nginx-ns --replicas=5 #---> to scale the deployment

##syntax 
 kubectl scale deployment/(name-of-deployment) -n (name-of-namespace) --replicas=(number-of-replicas)

kubectl set image deployment/nginx-deployment -n nginx-ns nginx-container=nginx:1.26.3   #---> to update the image of the deployment
##syntax
kubectl set image deployment/(deploy-name) -n (namespace-name) (container-name)=image-name:tag  
kubectl rollout status deployment/nginx-deployment -n nginx-ns  #---> to check the status
kubectl rollout history deployment/nginx-deployment -n nginx-ns  #---> to check the history
kubectl rollout undo deployment/nginx-deployment -n nginx-ns  #---> to undo the last deployment
kubectl rollout undo deployment/nginx-deployment -n nginx-ns --to-revision=1  #---> to undo to a specific revision
kubectl rollout pause deployment/nginx-deployment -n nginx-ns  #---> to pause the deployment
kubectl rollout resume deployment/nginx-deployment -n nginx-ns  #---> to resume the deployment

## DaemonSets
daemonsets unsure krta hain ki har ek node me ek pod run krta rahe

##
kubectl get job      #---> to see all jobs
kubectl get job -n nginx-ns  #---> to see all jobs in a specific namespac
kubectl get job -n nginx-ns -o wide  #---> to see all jobs in a specific namespace with more details
##
kubectl logs pod/(name-of-pod-created) -n nginx-ns #---> to see the logs of the po
##
kubectl get cronjobs -n nginx-ns    #---> to see all cronjobs in a specific namespace
kubectl get cronjobs -n nginx-ns -o wide  #---> to see all cron

## Storage classes
kubectl get sc      #---> to see all storage classes
kubectl get sc -n nginx-ns  #---> to see all storage classes in a specific namespace
kubectl get sc -n nginx-ns -o wide  #---> to see all storage classes in a specific namespace with more details

#type of storage classes
1. local
2. ceph
3. csi

kubectl get pv    #---> to see all persistent volumes
kubectl get pv -n nginx-ns  #---> to see all persistent volumes in a specific namespace
kubectl get pv -n nginx-ns -o wide  #---> to see all persistent volumes in a specific namespace with more details 

kubectl get all    #---> to see all resources in the cluster
kubectl get all -n nginx-ns  #---> to see all resources in a specific namespace

kubectl get svc    #---> to see all services
kubectl get svc -n nginx-ns  #---> to see all services in a specific namespace
kubectl get svc -n nginx-ns -o wide  #---> to see all services in wide 

kubectl port-forward service/nginx-service -n nginx-ns 80:80 --address=0.0.0.0    #---> to forward the port of the service
#syntax
kubectl port-forward service/(service-name) -n (namespac) (local-port):(remote-port) --address=0.0.0.0

# What is ingress?
Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. Traffic routing is controlled by rules defined on the Ingress resource

client -> ingress managed LB -> routing rule -> service -> pods
                                                        -> pods 


kubectl apply -f https://kind.sigs.k8s.io/examples/ingress/deploy-ingress-nginx.yaml   #---> to deploy ingress nginx
kubectl get ingress -n nginx-ns  #---> to see all ingress in a specific namespace


##Probe (request)

1.liveness probe
2.readiness probe
3.startup probe


## Taints/Tolerations

Taints: Mark a node as tainted, so that pods cannot be scheduled on it unless they have the matching tolerance
# means it marks as do not use this node

Tolerations: Allow a pod to be scheduled on a tainted node, if it has the matching tolerance
# means it allows to use this node

kubectl taint node multi-node-worker1 prod=true:NoSchedule
#Syntax
kubectl taint node (node-name) (key)=(value): (effect)    #---> to taint a node 

#effect
1. NoSchedule
2. NoExecute
3. PreferNoSchedule

kubectl untaint node multi-node-worker1
#Syntax
kubectl untaint node (node-name)        #---> to untaint a node

kubectl get nodes -o wide      #---> to check which nodes are tainted

##Types of auto scalling
1.HPA (Horizontal pod auto scalling)   #---> to scale the number of replicas of a pod
2.VPA (Vertical pod auto scalling)   #---> to scale the resources of a pod
3.KEDA (Kubernetes event-driven autoscaling)    #---> to scale the number of replicas of a pod based on 
#the number of events

#HPA
kubectl autoscale deployment my-deployment --min=1 --max=10 --cpu-percent=50
#Syntax
kubectl autoscale deployment (deployment-name) --min=(min-replicas) --max=(max-replicas) --cpu-percent=(cpu-percent)    #---> to create a HPA
kubectl delete hpa my-hpa         #---> to delete a HPA
kubectl get hpa -o wide         #---> to get all HPA
kubectl get hpa my-hpa -o yaml    #---> to get the status of a HPA

#VPA
kubectl create vpa --namespace default --name my-vpa --target-references my-deployment
#Syntax
kubectl create vpa --namespace (namespace) --name (vpa-name) --target-references
#(target-deployment)    #---> to create a VPA
kubectl delete vpa my-vpa         #---> to delete a VPA
kubectl get vpa -o wide         #---> to get all VPA
kubectl get vpa my-vpa -o yaml    #---> to get the status of a VPA

#KEDA
kubectl create keda --namespace default --name my-keda --target-references my-deployment
#Syntax
kubectl create keda --namespace (namespace) --name (keda-name) --target-references (target-deployment)   #---> to create a KEDA

#what is Metrics
Metrics are the data that is collected from the cluster, such as CPU usage, memory usage, and
network traffic. This data is used to make decisions about the cluster, such as scaling up or down
or identifying performance issues.

##install metric-server on a kind-cluster
1. kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

2.kubectl -n kube-system edit deployment metrics-server
3. ##add this in container in args
- --kubelet-insecure-tls
- --kubelet-preferred-address-types=InternalIP,Hostname,ExternalIP

4. kubectl -n kube-system rollout restart deployment metrics-server
5.
kubectl get pods -n kube-system
kubectl top nodes



kubectl run -i --tty load-generator --image=busybox -n apache -- /bin/sh    #---> to run a pod in interactive mode
#syntax
kubectl run -i --tty (pod-name) --image (image-name) -n (namespace) -- (command/shelltype)        #--> to run a pod in interactive mode

while true; do wget -q -O- http://load-generator.default.svc.cluster.local; done      #----> to run on loop / stress app
#syntax
while true; do (command) ; done      #---> to run on loop / stress app

##For VPA
git clone https://github.com/kubernetes/autoscaler.git
cd autoscaler/vertical-pod-autoscaler
./hack/vpa-up.sh

# What is Node affinity
Node affinity is a way to specify which nodes a pod can run on. It is used to ensure 
that a pod runs on a node that has the required resources and meets the specified requirements.

# RBAC (Role -Based Access Control)
RBAC is a way to control access to resources in a cluster. It is used to ensure that
users and groups have the correct permissions to perform actions on resources.

Namespace: Roles, RoleBinding
Cluster: ClusterRole, ClusterRoleBinding
# RBAC
kubectl create clusterrolebinding my-cluster-role-binding --clusterrole=my-cluster-role --user=my-user
#syntax
kubectl create clusterrolebinding (cluster-role-binding-name) --clusterrole=(cluster-role-name) --user=(user-name)      #---> to create a cluster role binding
# RBAC


1. Service Account:
kubectl get sa          #--> to get all service accounts
kubectl get sa -o yaml  #--> to get all service accounts in yaml format
kubectl get sa -o wide  #--> to get all service accounts in wide format
2. Roles
kubectl get roles      #--> to get all roles
kubectl get roles -o yaml  #--> to get all roles in yaml format
kubectl get roles -o wide  #--> to get all roles in wide format
kubectl create role my-role --verb=get --verb=list --verb=watch --resource=pods --namespace=my-namespace
#syntax
kubectl create role (role-name) --verb=(verb) --resource=(resource)      #---> to create a role
3. Role Bindings
kubectl get rolebindings      #--> to get all role bindings
kubectl get rolebindings -o yaml  #--> to get all role bindings in yaml format
kubectl get rolebindings -o wide  #--> to get all role bindings in wide format
kubectl create rolebinding my-role-binding --role=my-role --user=my-user --namespace=my-namespace
#syntax
kubectl create rolebinding (role-binding-name) --role=(role-name) --user=(user-name) --namespace=(namespace-name)      #---> to create a role binding
4. Cluster Roles
kubectl get clusterroles      #--> to get all cluster roles
kubectl get clusterroles -o yaml  #--> to get all cluster roles in yaml format
kubectl get clusterroles -o wide  #--> to get all cluster roles in wide format
kubectl create clusterrole my-cluster-role --verb=get --verb=list --verb=watch --resource=pods 
#syntax
kubectl create clusterrole (cluster-role-name) --verb=(verb) --resource=(resource) #---> to create a cluster role
5. Cluster Role Bindings
kubectl get clusterrolebindings      #--> to get all cluster role bindings
kubectl get clusterrolebindings -o yaml  #--> to get all cluster role bindings in yaml format
kubectl get clusterrolebindings -o wide  #--> to get all cluster role bindings in wide format
kubectl create clusterrolebinding my-cluster-role-binding --clusterrole=my-cluster-role --user=my-user
#syntax
kubectl create clusterrolebinding (cluster-role-binding-name) --clusterrole=(cluster-role-name) --user=(user-name)   #---> to create a cluster role binding

kubectl auth whoami    #---> to get the current user

kubectl apply -f .   #---> to apply the configuration in the current directory/folder all included YAML files will be run
kubectl delete -f .   #---> to delete the configuration in the current directory/folder all included YAML files will be run

kubectl auth can-i get pods --as=my-user  #---> to check if the user has the permission to get
#syntax
kubectl auth can-i (verb) (resource) --as=(user-name)      #---> to check if the user has the permission to perform the action

apiGroups:
- apiextensions.k8s.io    #---> used in 
- apps                #---> used in Deployment version
- authentication.k8s.io  #---> used in 
- autoscaling            #---> used in autoscliing version
- batch          #used in 
- certificates.k8s.io    #---> used in 
- core
- extensions
- networking.k8s.io
- policy
- rbac.authorization.k8s.io   #---> used in RBAC Yaml version
- storage.k8s.io

Resources:
- configmaps
- cronjobs
- deployments
- events
- jobs
- limitranges
- namespaces
- nodes
- persistentvolumeclaims
- persistentvolumes
- pods
- replicationcontrollers
- resourcequotas
- secrets
- serviceaccounts
- services
- storageclasses
- volumes

Verbs:
- create
- delete
- get
- list
- patch
- read
- update

#################################################################################################33

#setting up dashboard

kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
kubectl get deployments -n kubernetes-dashboard

apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard


kubectl apply -f dashboard-admin-user.yml
kubectl -n kubernetes-dashboard create token admin-user
kubectl proxy --port --address=0.0.0.0 --accept-hosts='*' #--> this will expose the dashboard on port 8001 on your local machine
kubectl proxy ----> this will expose on 127.0.0.1  

http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/

###############################################################################################

CRDs (Custom Resource Definitions):

It is to craete a custom resource definition. This is used to create a custom resource. The custom resource definition is used
to define the schema of the custom resource. The custom resource definition is used to define the structure of
the custom resource. The custom resource definition is used to define the fields of the custom resource.

kubectl get crd -A   #---> to get all the custom resource definitions in the cluster
kubectl get crd -A --all-namespaces #---> to get all the custom resource definitions

#########################################################################################################

Helm:
helm is package manager for kubernetes

#Chart Management
helm create <name>                      # Creates a chart directory along with the common files and directories used in a chart.
helm package <chart-path>               # Packages a chart into a versioned chart archive file.
helm lint <chart>                       # Run tests to examine a chart and identify possible issues:
helm show all <chart>                   # Inspect a chart and list its contents:
helm show values <chart>                # Displays the contents of the values.yaml file
helm pull <chart>                       # Download/pull chart 
helm pull <chart> --untar=true          # If set to true, will untar the chart after downloading it
helm pull <chart> --verify              # Verify the package before using it
helm pull <chart> --version <number>    # Default-latest is used, specify a version constraint for the chart version to use
helm dependency list <chart>            # Display a list of a chart’s dependencies:

#Install and Uninstall Apps
helm install <name> <chart>                           # Install the chart with a name
helm install <name> <chart> -n <namespace> --create-namespace  # Install the chart with a name and create a namespace if it does not exist
helm install <name> <chart> --namespace <namespace>   # Install the chart in a specific namespace
helm install <name> <chart> --set key1=val1,key2=val2 # Set values on the command line (can specify multiple or separate values with commas)
helm install <name> <chart> --values <yaml-file/url>  # Install the chart with your specified values
helm install <name> <chart> --dry-run --debug         # Run a test installation to validate chart (p)
helm install <name> <chart> --verify                  # Verify the package before using it 
helm install <name> <chart> --dependency-update       # update dependencies if they are missing before installing the chart
helm uninstall <name>                                 # Uninstall a release

#Perform App Upgrade and Rollback
helm upgrade <release> <chart>                            # Upgrade a release
helm upgrade <release> <chart> --atomic                   # If set, upgrade process rolls back changes made in case of failed upgrade.
helm upgrade <release> <chart> --dependency-update        # update dependencies if they are missing before installing the chart
helm upgrade <release> <chart> --version <version_number> # specify a version constraint for the chart version to use
helm upgrade <release> <chart> --values                   # specify values in a YAML file or a URL (can specify multiple)
helm upgrade <release> <chart> --set key1=val1,key2=val2  # Set values on the command line (can specify multiple or separate valuese)
helm upgrade <release> <chart> --force                    # Force resource updates through a replacement strategy
helm rollback <release> <revision>                        # Roll back a release to a specific revision
helm rollback <release> <revision>  --cleanup-on-fail     # Allow deletion of new resources created in this rollback when rollback fails

#List, Add, Remove, and Update Repositories
helm repo add <repo-name> <url>   # Add a repository from the internet:
helm repo list                    # List added chart repositories
helm repo update                  # Update information of available charts locally from chart repositories
helm repo remove <repo_name>      # Remove one or more chart repositories
helm repo index <DIR>             # Read the current directory and generate an index file based on the charts found.
helm repo index <DIR> --merge     # Merge the generated index with an existing index file
helm search repo <keyword>        # Search repositories for a keyword in charts
helm search hub <keyword>         # Search for charts in the Artifact Hub or your own hub instance

#Helm Release monitoring
helm list                       # Lists all of the releases for a specified namespace, uses current namespace context if namespace not specified
helm list --all                 # Show all releases without any filter applied, can use -a
helm list --all-namespaces      # List releases across all namespaces, we can use -A
helm list -l key1=value1,key2=value2 # Selector (label query) to filter on, supports '=', '==', and '!='
helm list --date                # Sort by release date
helm list --deployed            # Show deployed releases. If no other is specified, this will be automatically enabled
helm list --pending             # Show pending releases
helm list --failed              # Show failed releases
helm list --uninstalled         # Show uninstalled releases (if 'helm uninstall --keep-history' was used)
helm list --superseded          # Show superseded releases
helm list -o yaml               # Prints the output in the specified format. Allowed values: table, json, yaml (default table)
helm status <release>           # This command shows the status of a named release.
helm status <release> --revision <number>   # if set, display the status of the named release with revision
helm history <release>          # Historical revisions for a given release.
helm env                        # Env prints out all the environment information in use by Helm.

#Download Release Information
helm get all <release>      # A human readable collection of information about the notes, hooks, supplied values, and generated manifest file of the given release.
helm get hooks <release>    # This command downloads hooks for a given release. Hooks are formatted in YAML and separated by the YAML '---\n' separator.
helm get manifest <release> # A manifest is a YAML-encoded representation of the Kubernetes resources that were generated from this release's chart(s). If a chart is dependent on other charts, those resources will also be included in the manifest.
helm get notes <release>    # Shows notes provided by the chart of a named release.
helm get values <release>   # Downloads a values file for a given release. use -o to format output

#Plugin Management
helm plugin install <path/url1>     # Install plugins
helm plugin list                    # View a list of all installed plugins
helm plugin update <plugin>         # Update plugins
helm plugin uninstall <plugin>      # Uninstall a plugin

#############################################################################
What is Service Mesh ?
A service mesh is a configurable infrastructure layer for microservices applications. 
It makes communication between services easier,more reliable, and more secure. 
It provides features such as service discovery, load balancing, circuit breaking

Service Mesh Tool:
- Istio
- Linkerd
- Consul
- Service Mesh Interface (SMI)
- Open Service Mesh (OSM)
- Kuma
- AWS App Mesh
- Google Service Mesh
- Azure Service Mesh




