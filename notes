#Q. what is Kuberentes?
- an open-source container orchestration system for automating the deployment, scaling, and management of container
- it was originally designed by google, and is now maintained by the cloud native computing foundation
- it allows for the deployment of applications and services in a scalable and highly available manner
- it provides a lot of features such as self-healing, load balancing, and resource management
- it is a hybrid cloud platform that can run on-premises and in the cloud
- kubernetes have self managing and self healing ability once deployed correctly.
- we can also use upto 100% of our resources in kubernetes.
- By default kubernetes port starts from 30000 to 32767.

## Kubernetes Architrcture
 # components:-
  Control Plane/Master Node
   Kube API server
   Etcd
   Scheduler
   Controller Manager
  Worker Node
   Kubelet
   Kube Proxy
   Container runtime
   Pods

 # Master Node (Control Plane)
 The brain of Kubernetes, managing the entire cluster.
 Key Components:-
  1. API Server
     - Acts as the front door for the cluster.
     - Processes commands from users (kubectl) or other tools.
     - Communicates with all other components.
     - Ensures security and authentication.
    
  2. Scheduler
     - Decides which worker node will run a new pod.
     - Matches resources (CPU, memory) with pod requirements.
     - Ensures workload is evenly distributed.
    
  3. Controller Manager
     - Monitors the cluster to ensure the desired state is met.
     - Restarts pods if they crash.
     - Handles tasks like scaling and maintaining services.
    
  4. etcd
     - A key-value store that holds all cluster data.
     - Keeps track of the cluster’s state and configuration.
     - Highly available and distributed.
  
 # Worker Node
 Where your application runs.
 Key Components:-
  1. Kubelet
   - The worker node’s "agent."
   - Ensures containers are running as per instructions from the master node.
   - Communicates with the API Server.
  
  2. Kube-Proxy
   - Manages network rules and routes traffic to the right pod.
   - Ensures pods within the cluster can communicate.
   - Handles services like load balancing.

  3. Container Runtime
   - Runs containers on the worker node.
   - Examples: Docker, containerd, CRI-O.
   - Executes, stops, and monitors the containers.  

  4. Pod
   - A pod is the basic building block in Kubernetes.
   - Pods are temporary by design. Kubernetes can destroy and recreate pods to maintain the desired state or in response to failures.
   - Containers in the same pod share resources such as networking and storage.


## Steps to install kubernetes
 (reference - https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html)

## To install 'kubectl'
curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.30.6/2024-11-15/bin/linux/amd64/kubectl
chmod +x ./kubectl
mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$HOME/bin:$PATH
echo 'export PATH=$HOME/bin:$PATH' >> ~/.bashrc

## To install 'eksctl'
# for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`
ARCH=amd64
PLATFORM=$(uname -s)_$ARCH
curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
# (Optional) Verify checksum
curl -sL "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check
tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz
sudo mv /tmp/eksctl /usr/local/bin


## Commands
  # To run a 'cluster' from CLI
   ** Give a IAM role of admin to the ec2 instance to create a cluster from CLI.
   eksctl create cluster --name <our_name> --node-type <node/instance_type> --nodes <no._of_nodes> --region=<region>
  # To delete a cluster from CLI
   eksctl delete cluster --name <our_name> --region=<region>

  kubectl get pods -A --> to see all pods 
  vim pod.yaml --> pod manifest file
  kubectl apply -f pod.yaml --> to apply manifest
  kubectl get pod/po --> small commands to see pods
  kubectl describe pod/po nginx --> to describe pods nginx 

# Manifest
 Pod 
 RS 
 Deployment
 SERVICES
  LB -> Loadbalancer
  NP -> Network Policy
  CIP -> ClusterIP
 Confg
  services
  CMP
 Namespace
 Resource replca

 ingress
 volumes
 HPD


 # POD Maifest syntax: (interview question)
 apiVersion: v1
 kind: Pod
 metadata:
  name: nginx
 spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80

client and cluster can work on version that are 1 or 2 version apart not more than that.
# command
kubectl exec -it <pod_name> -- /bin/bash --> to go inside pod
we can add "-n namespace_name" to go inside different namespaces.

temporary alias set --> alias k=kubectl
create permenant alias --> edit /etc/bashrc and add alias k=kubectl at the bottom


## ReplicaSet
 It maintains a stable set of replicas (pods) running at any given time. Even if we delete a pod of the replicaset it will 
 automatically make a new pod. 
 Uses label selectors to identify which pods it manages.

#demo replicaset file:-
filename --> replicaset.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx
  labels:
    app: nginx-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-rs
  template:
    metadata:
      labels:
        app: nginx-rs
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80

command to list replicaset --> kubectl get rs
** command to scale replicaset --> kubectl scale --replicas=(no._of_pods) rs/(RS_name) **


# Deployment
 Deployment is a higher-level concept that manages ReplicaSets. 
 As a user we create a deployment set that creates the replicasets and manages it.
 It can be used to manage multiple ReplicaSets at the same time.
 If we want to update a the pod we can do that easily without any downtime using deployment. As it will update one pod and direct its
 traffic to other pods or can create new pod. It will do this for each pod to avoid downtime. this increase in pods to update change is called 
 rollout update.

 We can make changes to our go back to previous changes in deployment.
 command --> kubectl rollout undo deployment/(deployment_name)

#demo deployment file:-
filename --> deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80

command to list deployments --> kubectl get deploy/deployment/deployments

# Hirerchy--> deployment -> ReplicaSet -> pod (deploy creates replicaset which then creates pods)       
kubctl api-resources --> to check all the api resources available in the cluster.


## SERVICES
 
 LB -> Loadbalancer -> this service is available only on cloud and not on onprem.
  by default it supports classic loadbalancer. #Q. can we use other type of LB?

 NP -> Network Port -> this is used to define the service on the port of the node.
  it works when our node have a public ip to it.

 CIP -> ClusterIP - default service of a cluster. 

# demo service manifest file:-
filename --> service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: MyApp # the selector should match the label in the deployment to attach srvice to it otherwise it will not be attached.
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376  

we can use different manifest in a single yaml file by using --- separator.
eg:-
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    app.kubernetes.io/name: proxy
spec:
  containers:
  - name: nginx
    image: nginx:stable
    ports:
      - containerPort: 80
        name: http-web-svc # 

---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app.kubernetes.io/name: proxy
  ports:
  - name: name-of-service-port
    protocol: TCP
    port: 80
    targetPort: http-web-svc

#commands
kubectl get service -> to get service
kubectl get service -A -> to get all services in namespaces
kubectl get service -o wide -> to get additional information about service

# imperative / declarative --> way of creating service
# commands  / manifest  

#Q. Difference between Replicaset and Deployment? interview que
#Q. How can do we upgrade pods in kubernetes if the user is live?
#Q. Difference between services i.e. LB,NP and CIP

## Config Map
- non-confidential information are sent and stored by configmap.
- 
 # commands
 This command will create a configmap directly from the data we gave it in the command itself.
 kubectl create configmap/cm (configmap_name) --from-literal=KEY=VALUE .. 
 eg:- kubectl create configmap/cm exampleconfigmap --from-literal=1_database_name=data1 --from-literal=2_database_name=data2

 If we have one or more files that contains data and we want to create a configmap from those files,
 we can do that with the following command.
 imperative way: kubectl create configmap/cm (configmap_name) --from-file=KEY=VALUE ..
 eg:- kubectl create configmap/cm exampleconfigmap --from-file=data1.txt --from-file=data2.txt

 If we have a directory that contains the files that contains imp data and we want to make a configmap from those files.
 kubectl create configmap/cm (configmap_name) --from-file=directory_name/ 
 eg:- kubectl create configmap/cm exampleconfigmap --from-file=demo_dir/

#demo configmap yaml file:-
apiVersion: v1
kind: ConfigMap
metadata:
 name: exampleconfigmap
data:
 1_database_name: data1
 2_database_name: data2
we can create a config map from a yaml file like this.
To use a configmap in a pod, we need to "reference" it in the pod spec.
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mypod
    image: nginx:1.14.1
    envform:
    - configMapRef:
     name: exampleconfigmap
To use a configmap in a pod as a "Volume", we need to provide the path where the pod to be attached and provide the configmap.
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mypod
    image: nginx:1.14.1
    volumeMounts:
    - name: examplevolumemount
      mountPath: "/config"
      readOnly: "true"
  Volumes:
   - name: examplevolumemount
     configMap:
      name: exampleconfigmap

 declarative way:
 first create a yaml file by dry running a configmap file
 kubectl create configmap/cm nginx-cm --from-file=index.html --dry-run=client -o yaml > cm.yaml

 then make changes in the created yaml file.
 (reffer to sir repo)
 
 ## secret
- confidential information are sent and stored by secret.
- it encodes the data in base64.
- it is used to store sensitive information such as database credentials, api keys, etc.
 
 #commands
 kubectl secret --help --> to get all the options.

 kubectl create secret generic (secret_name) --from-literal=KEY=VALUE ..
 eg:- kubectl create secret generic mysecret --from-literal=name=prathamesh
 This command will create a secret named mysecret with a key named name and value prathamesh and it will encrypt the value in base64.
 
 kubectl get secret --> to get all the secrets.
 kubectl get secret <secret_name> --> to get a specific secret.
 kubectl get secret <secret_name> -o yaml--> to get the content of a specific secret. But it will be encrypted in base64.
 echo <base64 encoded string> | base64 --decode/-d --> to decode the base64 encoded string.

# demo secret yaml file:-
apiVersion: v1
kind: Secret
metadata:
 name: exampleSecret
data:
 1_password: "hello"
 2_password: "world"

To use secret as a volume in pod.
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mypod
    image: nginx:1.14.1
    volumeMounts:
    - name: secretvolumemount
      mountPath: "/secret"
  Volumes:
   - name: secretvolumemount
     secret:
      secretName: exampleSecret


## Persistant Volume (PV)
- When we store data in a pod, it is not persistent. It will be deleted when the pod is restarted or deleted.
- Persistant volume ensures that the data is stored even after the pod is restarted or deleted.
- We use PVC(persistant volume claim) to use the PV in our pod. PV can not be used directly in pod.
- The PV should match the PVC(persistant volume claim) in terms of storage size and access mode while writing it in a yaml file.

# demo yaml file of Persistant Volume (PV):-
apiVerssion : v1
kind: PersistentVolume
metadata: 
 name: example-pv
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/data"

# demo yaml file of Persistant Volume Claim(PVC):-
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: example-pvc
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi
 
 # demo yaml pod file using pvc as volume:- 
apiVersion: v1
kind: Pod
metadata:
  name: example-pod
spec:
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
        claimName: example-pvc
  containers:
    - name: task-pv-container
      image: nginx
      ports:
        - containerPort: 80
          name: "http-server"
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: task-pv-storage

In above first we create a PV to allocate storage space on the host machine. Then we create a PVC to request storage space from
the cluster. Then we assigned the PVC as a volume to the pod. The pod can now use the storage space allocated by the PV.

 Types:
 Host 
 Addons
 fsx is for windows

 Volume Add-ons:
 These are extensions or plugins that enhance how Kubernetes handles storage.
 Types of Kubernetes Volume Add-ons:-(some of the types)
  Container Storage Interface (CSI)
  Persistent Volume Claims (PVC) Enhancers
 
 Container Storage Interface (CSI)


## Namespace
- a logical grouping of resources.
- Namespace is not specified to a node it is seen across the cluster.

 # command 
 imperative way: kubectl create namespace/ns (namespace_name)


 